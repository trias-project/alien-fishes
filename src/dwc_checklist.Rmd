---
title: "Darwin Core mapping"
subtitle: "For dataset: Checklist of alien fishes in Flanders, Belgium"
author:
- Lien Reyserhove
- Dimitri Brosens
- Peter Desmet
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    theme: yeti
    df_print: paged
knit: (function(input_file, encoding) { rmarkdown::render(input_file, encoding = encoding, output_file = paste0("../docs/",sub(".Rmd", ".html", basename(input_file))))})
---

This document describes how we map the checklist data to Darwin Core.

# Setup

```{r, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Set locale (so we use UTF-8 character encoding):

```{r, eval = F}
# This works on Mac OS X, might not work on other OS
Sys.setlocale("LC_CTYPE", "en_US.UTF-8")
```

Load libraries:

```{r}
library(tidyverse) # For data transformations

# None core tidyverse packages:
library(magrittr)  # For %<>% pipes

# Other packages
library(janitor)   # For cleaning input data
library(readxl)    # To read excel files
library(stringr)   # to perform string operations
library(digest)    # To generate hashes
```

Set file paths (all paths should be relative to this script):
 
```{r}
# Raw files:
raw_data_file = "../data/raw/ExotischeVissenVlaanderen2016.xlsx"

# Processed files:
dwc_taxon_file = "../data/processed/taxon.csv"
dwc_vernacular_file = "../data/processed/vernacularname.csv"
dwc_distribution_file = "../data/processed/distribution.csv"
dwc_description_file = "../data/processed/description.csv"
```

# Read data

Create a data frame `raw_data` from the source data:

```{r}
# Read the source data:
raw_data <- read_excel(raw_data_file, sheet = "Checklist", na = "NA") 

# Clean the data somewhat: remove empty rows if present
raw_data %<>%
  remove_empty_rows() %>%     # Remove empty rows
  clean_names()               # Have sensible (lowercase) column names
```

## Generate taxonID

To uniquely identify a taxon in the Taxon Core and reference taxa in the Extensions, we need a `taxonID`. Since we need it in all generated files, we generate it here in the raw data frame. It is a combination of `dataset-shortname:taxon:` and a hash based on the scientific name. As long as the scientific name doesn't change, the ID will be stable: 

```{r}
# Vectorize the digest function (The digest() function isn't vectorized. So if you pass in a vector, you get one value for the whole vector rather than a digest for each element of the vector):
vdigest <- Vectorize(digest)

# Generate taxonID:
raw_data %<>% mutate(taxon_id = paste("alien-fishes", "taxon", vdigest(latin_name, algo="md5"), sep=":"))
```

Further processing:

```{r}
# Add prefix `raw_` to all column names to avoid name clashes with Darwin Core terms:
colnames(raw_data) <- paste0("raw_", colnames(raw_data))

# Save those column names as a vector (makes it easier to remove them all later):
raw_colnames <- colnames(raw_data)
```
 
Preview data:

```{r}
head(raw_data)
```

# Create Taxon core

## Pre-processing

```{r}
taxon <- raw_data
```

## Term mapping
 
Map the source data to [Darwin Core Taxon](http://rs.gbif.org/core/dwc_taxon_2015-04-24.xml):
 
### language

```{r}
taxon %<>% mutate(language = "en")
```

### license

```{r}
taxon %<>% mutate(license = "http://creativecommons.org/publicdomain/zero/1.0/")
```

### rightsHolder

```{r}
taxon %<>% mutate(rightsHolder = "INBO")

```

### accessRights

```{r}
taxon %<>% mutate(accessRights = "http://www.inbo.be/en/norms-for-data-use")
```

### datasetID

```{r}
taxon %<>% mutate(datasetID = "")
```

### datasetName

```{r}
taxon %<>% mutate(datasetName = "Checklist of alien fishes in Flanders, Belgium")
```

### taxonID

```{r}
taxon %<>% mutate(taxonID = raw_taxon_id)
```

### scientificName

```{r}
taxon %<>% mutate(scientificName = raw_latin_name)
```

### kingdom

```{r}
taxon %<>% mutate(kingdom = "Animalia")
```

### taxonRank

All taxa are species:

```{r}
taxon %<>% mutate(taxonRank = "species")
```

### nomenclaturalCode

```{r}
taxon %<>% mutate(nomenclaturalCode = "ICZN")
```

## Post-processing

Remove the original columns:

```{r}
taxon %<>% select(-one_of(raw_colnames))
```

Preview data:

```{r}
head(taxon)
```

Save to CSV:

```{r}
write.csv(taxon, file = dwc_taxon_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Create Vernacular names extension

## Pre-processing

```{r}
vernacular_names <- raw_data
```

## Term mapping

Map the source data to [Vernacular Names](http://rs.gbif.org/extension/gbif/1.0/vernacularname.xml):

### taxonID

```{r}
vernacular_names %<>% mutate(taxonID = raw_taxon_id)
```

### vernacularName

Vernacular names are available in two languages: English (`raw_common_name`) and Dutch (`raw_nederlandse_naam`). We will gather these columns to generate a single column containing the vernacular name (`vernacularName`) and an additional column with the language (`language`):

```{r}
vernacular_names %<>%
  gather(key = language, value = vernacularName, raw_common_name, raw_nederlandse_naam, na.rm = TRUE, convert = TRUE) %>%
  select(-language, everything()) # Move language column to end
```

Sort on `taxonID` to keep information for a single taxon together:

```{r}
vernacular_names %<>% arrange(taxonID)
```

### language

This column currently contains the original column name, which we will recode to the ISO 639-1 language code:

```{r}
vernacular_names %<>% mutate(language = recode(language,
  "raw_common_name" = "en",
  "raw_nederlandse_naam" = "nl"
))
```

## Post-processing:

We remove the original columns. However, `raw_colnames` contains `raw_nederlandse_naam` and `raw_common_name`, which are removed in `vernacularnames` by gathering these columns in a single column. Thus, it is easier to remove all columns individually, instead of using `raw_colnames` :

```{r}
vernacular_names %<>% select(
  -raw_latin_name,
  -raw_origin,
  -raw_introduction,
  -raw_pathway_s,
  -raw_status,
  -raw_main_pathway,
  -raw_taxon_id)
```

Preview data:

```{r}
head(vernacular_names)
```

Save to CSV:

```{r}
write.csv(vernacular_names, file = dwc_vernacular_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Create Distribution extension
  
## Pre-processing

```{r}
distribution <- raw_data
```

## Term mapping

### taxonID

```{r}
distribution %<>% mutate(taxonID = raw_taxon_id)
```

### locationID

```{r}
distribution %<>% mutate(locationID = "ISO_3166-2:BE-VLG")
```

### locality

```{r}
distribution %<>% mutate(locality = "Flemish Region")
```

### countryCode

```{r}
distribution %<>% mutate(countryCode = "BE")
```

### occurrenceStatus

```{r}
distribution %<>% mutate(occurrenceStatus = "present")
```

### establishmentMeans

For `establishmentMeans` we follow the [GBIF controlled vocabulary](http://rs.gbif.org/vocabulary/gbif/establishment_means.xml) and just indicate that these species are `introduced` (= alien):

```{r}
distribution %<>% mutate(establishmentMeans = "introduced")
```

### eventDate

As all fishes in this checklist are established, the event date is assumed to range from the first year of introduction (`raw_introduction`) until now, expressed as `start_year/now`. First, we create `start_year` from `raw_introduction`:

```{r}
distribution %<>% mutate(start_year = raw_introduction)
```

Some `start_year` values are quite broad. We change these values to the first year for which an observation is plausible:

```{r}
distribution %<>% mutate(start_year = recode(start_year,
  "20xx" = "2000",
  "17th c." = "1601",
  "1980s" = "1980",
  "13th c." = "1201"
))
```

Create `current_year`:

```{r}
distribution %<>% mutate(current_year = "now")
```

Create `eventDate`:

```{r}
distribution %<>% mutate(eventDate = paste(start_year, current_year, sep = "/"))
```

Compare formatted dates with original dates in `raw_introduction`:

```{r}
distribution %>% 
  select (raw_introduction, eventDate)
```

## Post-processing

Remove the original columns:

```{r}
distribution %<>% select(-one_of(raw_colnames),
                         -start_year, -current_year)
```

Preview data:

```{r}
distribution %>% head()
```

Save to CSV:

```{r}
write.csv(distribution, file = dwc_distribution_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```

# Create Description extension

In the description extension we want to include **native range** (`raw_origin`), **pathway** (`raw_pathway_s`) and **invasion stage** (`raw_status`). We'll create separate data frames for all and then combine these with union.

## Native range

`raw_origin` contains native range information (e.g. `AS` for Asia). We'll separate, map and combine these values:

```{r}
native_range <- raw_data
```

Separate `raw_origin` on `" or "` in 2 columns:

```{r}
native_range %<>% separate(
  raw_origin,
  into = c("native_range_1", "native_range_2"),
  sep = " or ",
  remove = FALSE,
  convert = FALSE,
  extra = "merge",
  fill = "right"
)
```

Gather native ranges in a `key` and `value` column:

```{r}
native_range %<>% gather(
  key, value,
  native_range_1, native_range_2,
  na.rm = TRUE, # Also removes records for which there is no native_range_1
  convert = FALSE
)
```

Show values:

```{r}
native_range %>%
  select(value) %>%
  group_by(value) %>%
  summarize(records = n()) %>%
  arrange(value)
```

Map values:

```{r}
native_range %<>% mutate(mapped_value = recode(value,
  "AS" = "Asia",
  "EE" = "Eastern Europe",
  "AFR" = "Africa"))
```

Show mapped values:

```{r}
native_range %>%
  select(value, mapped_value) %>%
  group_by(value, mapped_value) %>%
  summarize(records = n()) %>%
  arrange(value) 
```

Drop the `key` and `value` columns and rename `mapped_value` as `description`:

```{r}
native_range %<>%
  select(-key, -value) %>%
  rename(description = mapped_value)
```

Create a `type` field to indicate the type of description:

```{r}
native_range %<>% mutate(type = "native range")
```

## Pathway

Information for `pathway` can be found in `raw_pathway_s`, which contains a list of introduction pathways. We'll separate, clean, map and combine these values:

```{r}
pathway <- raw_data
```

We separate `raw_pathway_s` in two separate columns:

```{r}
pathway %<>% separate(
  raw_pathway_s,
  into = c("pathway_1", "pathway_2"),
  sep = ", ",
  remove = FALSE,
  convert = FALSE,
  extra = "merge",
  fill = "right"
)
```

Gather pathways in a `key` and `value` column:

```{r}
pathway %<>% gather(
  key, value,
  pathway_1, pathway_2,
  na.rm = TRUE, # Also removes records for which there is no pathway_1
  convert = FALSE
)
```

Show unique values:

```{r}
pathway %>%
  distinct(value) %>%
  arrange(value)
```

We use the [standardized vocabulary](https://github.com/trias-project/vocab/tree/master/vocabulary) suggested for TrIAS to perform the mapping. This vocabulary is based on the [CBD standard](https://www.cbd.int/doc/meetings/sbstta/sbstta-18/official/sbstta-18-09-add1-en.pdf). This is a manually created overview of the abbreviations used in the dataset, their interpretation and the mapping to the CBD standard:

```{r, echo = F}
as.data.frame(matrix(data = c(
  "AM", "Active Migration", "corridor_water",
  "AN", "Angling/bait fish","escape_food_bait",
  "AQ", "Aquaculture", "escape_aquaculture",
  "BC", "Biological Control", "release_biologica_control",
  "BW", "Ballast Water", "stowaway_ballast_water",
  "OR", "Ornamental", "escape_ornamental",
  "UN", "Unintentional", "Unintentional"),
  nrow = 7, ncol = 3, 
  dimnames = list(c(1:7), c("abbreviation", "full name", "CBD mapping")),
  byrow = T))
```

Map the abbreviations to the CBD standard:

```{r}
pathway %<>% mutate(mapped_value = recode(value,
  "AM" = "corridor_water",
  "AN" = "escape_food_bait",
  "AQ" = "escape_aquaculture",
  "BC" = "release_biological_control",
  "BW" = "stowaway_ballast_water",
  "OR" = "escape_ornamental",
  "UN" = "unintentional" # Not part of CBD
))
```

Add the prefix `cbd_2014_pathway:` to refer to this standard (but not for `unintentional`, which has no alternative in the standard):

```{r}
pathway %<>% mutate(mapped_value = case_when (
  mapped_value != "unintentional" ~ paste("cbd_2014_pathway", mapped_value, sep = ":"),
  mapped_value == "unintentional" ~ mapped_value))
```

Show mapped values:

```{r}
pathway %>%
  select(value, mapped_value) %>%
  group_by(value, mapped_value) %>%
  summarize(records = n()) %>%
  arrange(value) 
```

Drop the `key` and `value` columns and rename `mapped_value` as `description`:

```{r}
pathway %<>%
  select(-key, -value) %>%
  rename(description = mapped_value)
```

Create a `type` field to indicate the type of description:

```{r}
pathway %<>% mutate(type = "pathway")
```

## Invasion stage

Information for `invasion stage` can be found in `raw_status`:

```{r}
invasion_stage <- raw_data
```

Recode values:

```{r}
invasion_stage %<>% mutate(description = recode(raw_status,
  "A" = "established",
  "A*" = "established",
  "N" = "naturalized"
))
```

Show mapped values:

```{r}
invasion_stage %>%
  select(raw_status, description) %>%
  group_by(raw_status, description) %>%
  summarize(records = n()) %>%
  arrange(raw_status) 
```

Create a `type` field to indicate the type of description:

```{r}
invasion_stage %<>% mutate(type = "invasion stage")
```

## Union native range, pathway and invastion_stage:

```{r}
description_ext <- bind_rows(native_range, pathway, invasion_stage)
```

## Term mapping

Map the source data to [Taxon Description](http://rs.gbif.org/extension/gbif/1.0/description.xml):

### taxonID

```{r}
description_ext %<>% mutate(taxonID = raw_taxon_id)
```

### description

```{r}
description_ext %<>% mutate(description = description)
```

### type

```{r}
description_ext %<>% mutate(type = type)
```

### language

```{r}
description_ext %<>% mutate(language = "en")
```

## Post-processing

Remove the original columns:

```{r}
description_ext %<>% select(
  -one_of(raw_colnames))
```

Move `taxonID` to the first position:

```{r}
description_ext %<>% select(taxonID, everything())
```

Sort on `taxonID` to group description information per taxon:

```{r}
description_ext %<>% arrange(taxonID)
```

Preview data:

```{r}
head(description_ext, 10)
```

Save to CSV:

```{r}
write.csv(description_ext, file = dwc_description_file, na = "", row.names = FALSE, fileEncoding = "UTF-8")
```
